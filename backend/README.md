# backend/README.md
# STT Pipeline Backend - PoC Phase 1

ë³¸ ì„œë²„ëŠ” Daiso ë§¤ì¥ ë‚´ AI ìƒí’ˆ ìœ„ì¹˜ ì•ˆë‚´ ì„œë¹„ìŠ¤ì˜ STT íŒŒì´í”„ë¼ì¸ ë°±ì—”ë“œì…ë‹ˆë‹¤.

## ğŸ“ í´ë” êµ¬ì¡°

```
backend/
â”œâ”€â”€ stt/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ types.py          # Pydantic íƒ€ì… ì •ì˜
â”‚   â”œâ”€â”€ adapters.py       # WhisperAdapter (faster-whisper)
â”‚   â”œâ”€â”€ quality_gate.py   # í’ˆì§ˆ ê²Œì´íŠ¸ (R1â†’R4)
â”‚   â””â”€â”€ policy_gate.py    # ì •ì±… ê²Œì´íŠ¸ (í‚¤ì›Œë“œ ê¸°ë°˜)
â”œâ”€â”€ config.yaml           # ì„¤ì • íŒŒì¼
â”œâ”€â”€ main.py               # FastAPI ì„œë²„
â”œâ”€â”€ runner.py             # CLI í…ŒìŠ¤íŠ¸ ëŸ¬ë„ˆ
â””â”€â”€ README.md
```

## ğŸš€ í™˜ê²½ ì„¤ì •

### 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (requirements.txt ì´ë¯¸ ì—…ë°ì´íŠ¸ë¨)
pip install faster-whisper pyyaml python-multipart

# ë˜ëŠ” ì „ì²´ requirements
pip install -r requirements.txt
```

### 2. GPU í™•ì¸

```bash
# NVIDIA GPU í™•ì¸
nvidia-smi

# CUDA ì‚¬ìš© ê°€ëŠ¥ í™•ì¸ (Python)
python -c "import torch; print(torch.cuda.is_available())"
```

## âš™ï¸ ì„¤ì • íŒŒì¼

`config.yaml`ì—ì„œ ë‹¤ìŒì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **STT ëª¨ë¸**: medium (ê¸°ë³¸), fallback: small
- **í’ˆì§ˆ ê²Œì´íŠ¸ ì„ê³„ê°’**: min_chars, min_confidence, nonsense_patterns
- **ê³ ì • ìœ„ì¹˜**: í™”ì¥ì‹¤/ê³„ì‚°ëŒ€/ì…êµ¬/ì¶œêµ¬ ì‘ë‹µ
- **ë¹„ì§€ì› í‚¤ì›Œë“œ**: ë°°ë‹¬/êµí™˜/í™˜ë¶ˆ ë“±

## ğŸ“ í…ìŠ¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ (ì˜¤ë””ì˜¤ íŒŒì¼ ë¶ˆí•„ìš”)

```bash
# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰
cd c:\Users\301\daiso-category-search-dev\daiso-category-search-dev
python backend/runner.py

# ê²°ê³¼ í™•ì¸
cat outputs/test_results.json
```

### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìˆ˜ì •

`data/test_cases.tsv`ë¥¼ í¸ì§‘í•˜ì—¬ ì¼€ì´ìŠ¤ ì¶”ê°€/ìˆ˜ì • ê°€ëŠ¥ (TSV í˜•ì‹)

## ğŸŒ FastAPI ì„œë²„ ì‹¤í–‰

### ë¡œì»¬ ê°œë°œ ì„œë²„

```bash
# ë°±ì—”ë“œ í´ë”ì—ì„œ
python main.py

# ë˜ëŠ” uvicorn ì§ì ‘ ì‹¤í–‰
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

ì„œë²„ ì‹¤í–‰ í›„:
- API ë¬¸ì„œ: http://localhost:8000/docs
- Health check: http://localhost:8000/health

### API ì—”ë“œí¬ì¸íŠ¸

#### POST `/stt/process`
ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ STT íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

**Request**:
- `audio`: ì˜¤ë””ì˜¤ íŒŒì¼ (WAV ê¶Œì¥)
- `attempt`: ì‹œë„ íšŸìˆ˜ (1 ë˜ëŠ” 2)

**Response**:
```json
{
  "request_id": "uuid",
  "stt": {
    "text_raw": "í™”ì¥ì‹¤ ì–´ë””ì—ìš”",
    "confidence": 0.95,
    "lang": "ko",
    "latency_ms": 1234
  },
  "quality_gate": {
    "status": "OK",
    "is_usable": true,
    "reason": "OK"
  },
  "policy_intent": {
    "intent_type": "FIXED_LOCATION",
    "location_target": "restroom",
    "confidence": 1.0,
    "reason": "Matched fixed location keyword: 'í™”ì¥ì‹¤'"
  },
  "final_response": "í™”ì¥ì‹¤ì€ ë§¤ì¥ ë’¤ìª½ ì™¼í¸ì— ìˆìŠµë‹ˆë‹¤.",
  "processing_time_ms": 1500
}
```

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. faster-whisper ì„¤ì¹˜ ì‹¤íŒ¨
```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi

# cuDNNì´ í•„ìš”í•œ ê²½ìš°
pip install nvidia-cudnn-cu11
```

### 2. OOM (Out of Memory) ì—ëŸ¬
- `config.yaml`ì—ì„œ `model: "small"`ë¡œ ë³€ê²½
- ë˜ëŠ” `device: "cpu"`ë¡œ ë³€ê²½ (ëŠë¦¼)

### 3. íŒ¨í‚¤ì§€ import ì—ëŸ¬
```bash
# í˜„ì¬ ë””ë ‰í† ë¦¬ í™•ì¸
pwd

# backend í´ë”ì—ì„œ ì‹¤í–‰í•˜ëŠ”ì§€ í™•ì¸
cd c:\Users\301\daiso-category-search-dev\daiso-category-search-dev
```

## ğŸ“Š Decision Log ì—…ë°ì´íŠ¸

ëª¨ë¸ ë³€ê²½ ë˜ëŠ” ì„ê³„ê°’ ì¡°ì • ì‹œ `10_DECISION_LOG.md`ì— ê¸°ë¡:

```markdown
### 2026-01-16 â€” Whisper ëª¨ë¸ ì„ íƒ
- ê³„íš: large-v3
- ì‹¤ì œ: medium (RTX 3050 4GB ì œì•½)
- fallback: small
```

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

- [ ] NLU/ê²€ìƒ‰ ëª¨ë“ˆ ì—°ë™ (PRODUCT_SEARCH ì²˜ë¦¬)
- [ ] ì •ê·œí™” ëª¨ë“ˆ êµ¬í˜„ (07_NORMALIZATION.md)
- [ ] ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼ í…ŒìŠ¤íŠ¸
- [ ] Google STT ì–´ëŒ‘í„° êµ¬í˜„
- [ ] frontend ì—°ë™ (Next.js fetch ì˜ˆì‹œ)
